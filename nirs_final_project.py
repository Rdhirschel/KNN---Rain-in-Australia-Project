# -*- coding: utf-8 -*-
"""Nirs_Final_Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1j9FP409XuKl6AtWmD8AXw92fCSxdKAJR
"""

# General
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
# sklearn
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split
# Scalers
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import MinMaxScaler
# Encoder
from sklearn.preprocessing import LabelEncoder
# Metrics
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn import metrics

!git clone https://github.com/Rdhirschel/KNN---Rain-in-Australia-Project.git #clones the git files i need for the project

australia = pd.read_csv("/content/KNN---Rain-in-Australia-Project/weatherAUS.csv", parse_dates=['Date'])# makes the column a Date Time column

"""# Introduction to the dataset"""

# introduction:
australia.shape

australia.info()

australia.sample(5)

australia.isnull().sum().sort_values(ascending=False)

"""# Early Data Cleaning"""

# as we can see, there are some columns with a lot of NA values. I would like to drop ones that have more than 30% of the data gone:
min_amount = 0.3 * len(australia)
columns = australia.columns.tolist() # to list converts it to a list, self explanatory
for column in columns:
  if (australia[column].isnull().sum() >= min_amount):
    australia.drop(column, axis = 1, inplace=True)

australia.head()

australia.isnull().sum().sort_values(ascending=False)

"""It dropped the columns Sunshine, Evaporation, Cloud3pm, Cloud9am (>=30%)."""

australia.set_index("Date", inplace=True) #sets the Date as index

australia.head()

australia.RainTomorrow.unique() #Drop NA values of the label, since it is invalid data. We'll do the same for RainToday as well, since it is relatively hard to replace

australia = australia[(australia.RainTomorrow.isna() == False) & (australia.RainToday.isna() == False)] #drops na values
australia.isnull().sum().sort_values(ascending=False)

australia.fillna(australia.mean(), inplace=True) #all the other columns, fill na with corresponding mean

#Check there aren't any more null values:
australia.isnull().sum().sort_values(ascending=False)
#These are columns we will preform later One Hot Encoding, so it shouldn't be a problem (since they will just have 0 on all columns)

"""# Data Visualization"""

australia2017 = australia[(australia.index >= "2015-01-01") & (australia.index <= "2015-12-31")]
rainfall_byMonth = []
for month in range(1, 13):
    All_Days_In_Month = australia2017[australia2017.index.month == month]
    rainfall_byMonth.append((All_Days_In_Month['Rainfall'].sum(), month))

df_rainfallmonth = pd.DataFrame(rainfall_byMonth, columns=["Rainfall","Month"]) # turning the list to dataframe

df_rainfallmonth.plot(kind="bar", x="Month", y="Rainfall", title="Total Rainfall (mm.) by month in 2015, Australia", xlabel="Month", ylabel="Tot. Rainfall (mm.)", legend=False, figsize=(20,15))

all_locations_lst = australia.Location.unique()
graph = []
for location in all_locations_lst:
  avgMinTemp = np.average(australia[australia.Location == location].MinTemp)
  avgMaxTemp = np.average(australia[australia.Location == location].MaxTemp)
  graph.append((avgMinTemp, avgMaxTemp, location))

df_graph = pd.DataFrame(graph, columns=["AvgMinTemp", "AvgMaxTemp", "Location"])

df_graph.plot(kind="bar", x="Location", y = ["AvgMinTemp", "AvgMaxTemp"], xlabel = "Location", ylabel = "Temperature (Celsius)", title = "Temperature based on location, Australia", figsize=(20,15))

australia[["Pressure3pm", "Pressure9am", "RainTomorrow", "RainToday", "Temp9am", "Temp3pm", "WindGustSpeed", "WindSpeed9am", "WindSpeed3pm"]].hist(figsize=(15,20))

australia["RainTomorrow"].value_counts().plot.pie(autopct="%.1f%%", colormap = "winter", figsize=(10,10), title = "RainTommorow Percentage", fontsize = 16) # autopct="%.1f%%" - a way to show percentage on graph

directions = ['N', 'NNE', 'NE', 'ENE', 'E', 'ESE', 'SE', 'SSE', 'S', 'SSW', 'SW', 'WSW', 'W', 'WNW', 'NW', 'NNW']
rainyDir = australia[australia.RainToday == "Yes"]["WindGustDir"]

rainyDirCounts = rainyDir.value_counts()[directions] #Organizing it like compass rose (שושנת הרוחות)


rainyDirCounts.plot(kind='pie', figsize=(10, 10), colormap = "coolwarm", startangle=90, counterclock=False, autopct="%.1f%%", title="Frequency of Wind Gust Directions on Rainy Days in Australia")

"""# Label Encoding"""

features = australia.select_dtypes(include="object").drop(labels=['WindGustDir', 'WindDir9am', 'WindDir3pm'], axis=1) # those I think the One-Hot encoding approach would be more useful
for feature in features:
  australia[feature] = LabelEncoder().fit_transform(australia[feature])
australia.head()

"""# One Hot Encoding - Wind Directions"""

WindGustDir_dummies = pd.get_dummies(australia["WindGustDir"])
WindGustDir_dummies = WindGustDir_dummies.add_suffix("_Gust") # a way to distinguish between all of them

WindDir9am_dummies = pd.get_dummies(australia["WindDir9am"])
WindDir9am_dummies = WindDir9am_dummies.add_suffix("_9am")


WindDir3pm_dummies = pd.get_dummies(australia["WindDir3pm"])
WindDir3pm_dummies = WindDir3pm_dummies.add_suffix("_3pm")

#As an example lets print WindDir3pm_dummies to see what we get:
WindDir3pm_dummies.head()

# Now after we got the actual sets we will add them and remove the previous columns:
australia.drop(columns=["WindGustDir", "WindDir9am", "WindDir3pm"], inplace=True)
australia = pd.concat([australia, WindDir3pm_dummies, WindDir9am_dummies, WindGustDir_dummies], axis = 1)

#test if it worked:
print(f'australia shape: {australia.shape}')
australia.sample(5)

"""# MinMax Scaler"""

features_Scale = australia.columns.to_list()
features_Scale.remove("RainTomorrow")

for feature in features_Scale:
  australia[feature] = MinMaxScaler().fit_transform(australia[[feature]])
australia.sample(5)

"""# KNN Model"""

#Splitting the Dataset
features = australia.drop('RainTomorrow', axis=1)
label = australia.RainTomorrow
X = features.to_numpy()
y = label.to_numpy()


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.35, random_state = 14) #We have a lot of data, so i'll split accordingly
print(f'Xtrain = {X_train.shape}, ytrain = {y_train.shape}, Xtest = {X_test.shape}, ytest = {y_test.shape}')

KNN_Model = KNeighborsClassifier(n_neighbors=5)
KNN_Model.fit(X_train, y_train)

error = []
for k in range(3, 40,2): # This takes around 7-10 mins to load, so if you don't want to wait that long, set k = 11
    classifier = KNeighborsClassifier(n_neighbors=k)
    classifier.fit(X_train, y_train)
    predict = classifier.predict(X_test)

    returnvalue = (np.mean(predict != y_test), k)
    error.append(returnvalue)

#Graph:
ErrorRate = pd.DataFrame(error, columns = ['Rate', 'k'])
ErrorRate.head()

ErrorRate.plot(kind="line", x = 'k', y = 'Rate', linestyle='--', marker='o', color = 'Red', legend = False, figsize=(15,10), title="Error Rate with different k-values", xlabel="k", ylabel="Error Rate")

KNN_Model = KNeighborsClassifier(n_neighbors=11)
KNN_Model.fit(X_train, y_train)

"""# Evaluation"""

print(f'Accuracy: {accuracy_score(y_test, predict) * 100}')

matrix = confusion_matrix(y_test, predict)
matrix

cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = matrix, display_labels = ["Hasn't Rained", "Rained"])

cm_display.plot(cmap = "summer")

y_pred = KNN_Model.predict(X_test)
print(classification_report(y_test, y_pred)) # 0 - didn't rain, 1 - it has rained